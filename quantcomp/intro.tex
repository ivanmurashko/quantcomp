%% -*- coding:utf-8 -*- 
Algorithms play a significant role in computer science. An algorithm is a sequence of steps necessary to obtain an answer to a given problem. Each problem is characterized by a certain number, which determines its size. The complexity of an algorithm is assessed as the number of simple operations required to solve the given problem. Obviously, in most cases (but not always), this number grows with the size of the problem.

\begin{example}
\emph{Searching for an array element}
\label{exFind}
The task is to find an element of an array that meets certain conditions. The size of the problem is the number of elements in the array $N$.

In the general case (an unstructured array of data), the search is conducted by simple enumeration. This search requires a number of operations (comparisons) that grows linearly with the size of the array $O\left( N \right)$.

In the case of structured data, the number of operations required for the search can be reduced. For example, in the case of a sorted array, the complexity of the problem grows as $O\left(log N\right)$.
\end{example}

However, the existence of an algorithm does not yet guarantee its practical implementability. In particular, algorithms that require an exponential number of steps relative to the size of the original problem are considered practically unfeasible, despite the theoretical possibility of a solution.

One example is the problem of factoring a natural number, that is, the task of decomposing it into prime factors (see example \ref{exFactor}).

\begin{example}
\emph{Factorization of natural numbers}
\label{exFactor}
The task is to find the decomposition of a number into prime factors. The size of the problem is the digit length of the original number. For example, for the case of digit length $r = 4$: $1 \le N = 15 \le 2^r = 2^4 = 16$). The result can be found easily and quickly: $15 = 3 \cdot 5$.

As the number of digits $r$ increases, the number of operations required for factorization in classical algorithms grows as $O\left(2^r\right)$, which for the case $r = 1000 - 2000$ means the practical impossibility of factorizing such numbers.
\end{example}

Quantum objects have properties that differ from classical objects; accordingly, algorithms based on quantum objects can, in some cases, have characteristics inaccessible to classical algorithms. For example, Grover's quantum algorithm \cite{Grover96afast} solves the problem of searching an unstructured data array (see example \ref{exFind}) with $O\left(\sqrt{N}\right)$ operations. Shor's algorithm \cite{bShor94} allows solving the problem of factoring a number (see example \ref{exFactor}) using a linear number of operations $O\left(r\right)$. 